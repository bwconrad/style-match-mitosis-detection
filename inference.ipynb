{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as t\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from src.data import SimpleDataset\n",
    "from src.model import AdaInModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "resize_size = 0\n",
    "crop_size = 256\n",
    "\n",
    "if resize_size == 0:\n",
    "    transforms = t.Compose(\n",
    "        [\n",
    "            t.CenterCrop(crop_size),\n",
    "            t.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    transforms = t.Compose(\n",
    "        [\n",
    "            t.Resize(resize_size),\n",
    "            t.CenterCrop(crop_size),\n",
    "            t.ToTensor(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_visualize(imgs, titles=['Content', 'Style', 'Output']):\n",
    "    n = len(imgs)\n",
    "    plt.figure(figsize=(n*5, 10))\n",
    "\n",
    "    for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "        if len(img.size()) == 4:\n",
    "            img = img.squeeze(0)\n",
    "            \n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.imshow(img.permute(1,2,0).numpy())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer with Content and Style Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select content and style images\n",
    "content_dir = \"data/midog/1/\"\n",
    "style_dir = \"data/midog/4/\"\n",
    "style = {'description_width': 'initial'}\n",
    "c_widget = widgets.Dropdown(description='Content Image:', options=sorted(os.listdir(content_dir)), style=style)\n",
    "s_widget = widgets.Dropdown(description='Style Image:', options=sorted(os.listdir(style_dir)), style=style)\n",
    "\n",
    "display(c_widget)\n",
    "display(s_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "content_path = os.path.join(content_dir, c_widget.value)\n",
    "style_path = os.path.join(style_dir, s_widget.value)\n",
    "content_img = transforms(Image.open(os.path.join(content_path)).convert(\"RGB\"))\n",
    "style_img = transforms(Image.open(os.path.join(style_path)).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize images\n",
    "grid_visualize([content_img, style_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "#adain_checkpoint = \"output/adain_vanilla/version_0/checkpoints/epoch=13049-step=78299.ckpt\"\n",
    "#bfg_checkpoint = \"output/adain_bfg/version_0/checkpoints/epoch=12799-step=76799.ckpt\"\n",
    "#skip_checkpoint = \"output/adain_skip/version_0/checkpoints/epoch=12649-step=75899.ckpt\"\n",
    "adain_checkpoint = \"checkpoints/vanilla.ckpt\"\n",
    "bfg_checkpoint = \"checkpoints/bfg.ckpt\"\n",
    "skip_checkpoint = \"checkpoints/skip.ckpt\"\n",
    "\n",
    "adain_model = AdaInModel().load_from_checkpoint(adain_checkpoint)\n",
    "bfg_model = AdaInModel().load_from_checkpoint(bfg_checkpoint)\n",
    "skip_model = AdaInModel().load_from_checkpoint(skip_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla AdaIn\n",
    "with torch.no_grad():\n",
    "    out_vanilla, _, _ = adain_model(content_img.unsqueeze(0), style_img.unsqueeze(0))\n",
    "out_vanilla = out_vanilla.detach()\n",
    "grid_visualize([content_img, style_img, out_vanilla])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaIn with BFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaIn w/ BFG\n",
    "with torch.no_grad():\n",
    "    out_bfg, _, _ = bfg_model(content_img.unsqueeze(0), style_img.unsqueeze(0))\n",
    "out_bfg = out_bfg.detach()\n",
    "grid_visualize([content_img, style_img, out_bfg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaIn with BFG + Skip Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaIn w/ BFG + Skip Connections\n",
    "with torch.no_grad():\n",
    "    out_skip, _, _ = skip_model(content_img.unsqueeze(0), style_img.unsqueeze(0))\n",
    "out_skip = out_skip.detach()\n",
    "grid_visualize([content_img, style_img, out_skip])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualize([out_vanilla, out_bfg, out_skip], titles=[\"AdaIn\", \"+BFG\", \"+Skip\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Style Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_widget = widgets.Dropdown(description='Style Image 1:', options=sorted(os.listdir(style_dir)), style=style)\n",
    "s2_widget = widgets.Dropdown(description='Style Image 2:', options=sorted(os.listdir(style_dir)), style=style)\n",
    "s3_widget = widgets.Dropdown(description='Style Image 3:', options=sorted(os.listdir(style_dir)), style=style)\n",
    "\n",
    "display(s1_widget)\n",
    "display(s2_widget)\n",
    "display(s3_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_path1 = os.path.join(style_dir, s1_widget.value)\n",
    "style_path2 = os.path.join(style_dir, s2_widget.value)\n",
    "style_path3 = os.path.join(style_dir, s3_widget.value)\n",
    "\n",
    "style_img1 = transforms(Image.open(os.path.join(style_path1)).convert(\"RGB\"))\n",
    "style_img2 = transforms(Image.open(os.path.join(style_path2)).convert(\"RGB\"))\n",
    "style_img3 = transforms(Image.open(os.path.join(style_path3)).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualize([style_img1, style_img2, style_img3], titles=[\"Style 1\", \"Style 2\", \"Style 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_bfg1, _, _ = bfg_model(content_img.unsqueeze(0), style_img1.unsqueeze(0))\n",
    "    out_bfg2, _, _ = bfg_model(content_img.unsqueeze(0), style_img2.unsqueeze(0))\n",
    "    out_bfg3, _, _ = bfg_model(content_img.unsqueeze(0), style_img3.unsqueeze(0))\n",
    "\n",
    "out_bfg1 = out_bfg1.detach()\n",
    "out_bfg2 = out_bfg2.detach()\n",
    "out_bfg3 = out_bfg3.detach()\n",
    "\n",
    "grid_visualize([out_bfg1, out_bfg2, out_bfg3], titles=[\"Output 1\", \"Output 2\", \"Output 3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Images from Different Scanners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = \"data/midog/1/\"\n",
    "dir2 = \"data/midog/2/\"\n",
    "dir3 = \"data/midog/3/\"\n",
    "dir4 = \"data/midog/4/\"\n",
    "\n",
    "\n",
    "s1_widget = widgets.Dropdown(description='Style Scanner 1:', options=sorted(os.listdir(dir1)), style=style)\n",
    "s2_widget = widgets.Dropdown(description='Style Scanner 2:', options=sorted(os.listdir(dir2)), style=style)\n",
    "s3_widget = widgets.Dropdown(description='Style Scanner 3:', options=sorted(os.listdir(dir3)), style=style)\n",
    "s4_widget = widgets.Dropdown(description='Style Scanner 4:', options=sorted(os.listdir(dir4)), style=style)\n",
    "\n",
    "display(s1_widget)\n",
    "display(s2_widget)\n",
    "display(s3_widget)\n",
    "display(s4_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_path1 = os.path.join(dir1, s1_widget.value)\n",
    "style_path2 = os.path.join(dir2, s2_widget.value)\n",
    "style_path3 = os.path.join(dir3, s3_widget.value)\n",
    "style_path4 = os.path.join(dir4, s4_widget.value)\n",
    "\n",
    "style_img1 = transforms(Image.open(os.path.join(style_path1)).convert(\"RGB\"))\n",
    "style_img2 = transforms(Image.open(os.path.join(style_path2)).convert(\"RGB\"))\n",
    "style_img3 = transforms(Image.open(os.path.join(style_path3)).convert(\"RGB\"))\n",
    "style_img4 = transforms(Image.open(os.path.join(style_path4)).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualize([style_img1, style_img2, style_img3, style_img4], \n",
    "               titles=[\"Scanner 1\", \"Scanner 2\", \"Scanner 3\", \"Scanner 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_bfg1, _, _ = bfg_model(content_img.unsqueeze(0), style_img1.unsqueeze(0))\n",
    "    out_bfg2, _, _ = bfg_model(content_img.unsqueeze(0), style_img2.unsqueeze(0))\n",
    "    out_bfg3, _, _ = bfg_model(content_img.unsqueeze(0), style_img3.unsqueeze(0))\n",
    "    out_bfg4, _, _ = bfg_model(content_img.unsqueeze(0), style_img4.unsqueeze(0))\n",
    "    \n",
    "\n",
    "out_bfg1 = out_bfg1.detach()\n",
    "out_bfg2 = out_bfg2.detach()\n",
    "out_bfg3 = out_bfg3.detach()\n",
    "out_bfg4 = out_bfg4.detach()\n",
    "\n",
    "grid_visualize([out_bfg1, out_bfg2, out_bfg3, out_bfg4], \n",
    "               titles=[\"Scanner 1\", \"Scanner 2\", \"Scanner 3\", \"Scanner 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Images from Different Scanners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_widget = widgets.Dropdown(description='Content Scanner 1:', options=sorted(os.listdir(dir1)), style=style)\n",
    "c2_widget = widgets.Dropdown(description='Content Scanner 2:', options=sorted(os.listdir(dir2)), style=style)\n",
    "c3_widget = widgets.Dropdown(description='Content Scanner 3:', options=sorted(os.listdir(dir3)), style=style)\n",
    "c4_widget = widgets.Dropdown(description='Content Scanner 4:', options=sorted(os.listdir(dir4)), style=style)\n",
    "\n",
    "display(c1_widget)\n",
    "display(c2_widget)\n",
    "display(c3_widget)\n",
    "display(c4_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_path1 = os.path.join(dir1, c1_widget.value)\n",
    "content_path2 = os.path.join(dir2, c2_widget.value)\n",
    "content_path3 = os.path.join(dir3, c3_widget.value)\n",
    "content_path4 = os.path.join(dir4, c4_widget.value)\n",
    "\n",
    "content_img1 = transforms(Image.open(os.path.join(content_path1)).convert(\"RGB\"))\n",
    "content_img2 = transforms(Image.open(os.path.join(content_path2)).convert(\"RGB\"))\n",
    "content_img3 = transforms(Image.open(os.path.join(content_path3)).convert(\"RGB\"))\n",
    "content_img4 = transforms(Image.open(os.path.join(content_path4)).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualize([content_img1, content_img2, content_img3, content_img4], \n",
    "               titles=[\"Scanner 1\", \"Scanner 2\", \"Scanner 3\", \"Scanner 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_bfg1, _, _ = bfg_model(content_img1.unsqueeze(0), style_img.unsqueeze(0))\n",
    "    out_bfg2, _, _ = bfg_model(content_img2.unsqueeze(0), style_img.unsqueeze(0))\n",
    "    out_bfg3, _, _ = bfg_model(content_img3.unsqueeze(0), style_img.unsqueeze(0))\n",
    "    out_bfg4, _, _ = bfg_model(content_img4.unsqueeze(0), style_img.unsqueeze(0))\n",
    "    \n",
    "\n",
    "out_bfg1 = out_bfg1.detach()\n",
    "out_bfg2 = out_bfg2.detach()\n",
    "out_bfg3 = out_bfg3.detach()\n",
    "out_bfg4 = out_bfg4.detach()\n",
    "\n",
    "grid_visualize([out_bfg1, out_bfg2, out_bfg3, out_bfg4], \n",
    "               titles=[\"Scanner 1\", \"Scanner 2\", \"Scanner 3\", \"Scanner 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Content and Style Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_bfg, _, _ = bfg_model(style_img.unsqueeze(0), style_img.unsqueeze(0))\n",
    "    \n",
    "out_bfg = out_bfg.detach()\n",
    "\n",
    "grid_visualize([style_img, out_bfg], titles=[\"Original\", \"Output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Predefined Style Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_feats = torch.load(\"data/scanner4_features.pt\")\n",
    "avg_feats = torch.load(\"checkpoints/scanner4_features.pt\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out, _, _ = bfg_model(content_img.unsqueeze(0), style_img.unsqueeze(0))\n",
    "    out_avg, _, _ = bfg_model.net(content_img.unsqueeze(0), f_s=avg_feats)\n",
    "    \n",
    "out = out.detach()\n",
    "out_avg = out_avg.detach()\n",
    "\n",
    "grid_visualize([content_img, style_img, out, out_avg], titles=[\"Content\", \"Style\", \"Output\", \"Avg Features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_feats = []\n",
    "for f in avg_feats:\n",
    "    const_feats.append(torch.zeros_like(f).squeeze(0))\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_ones, _, _ = bfg_model.net(content_img.unsqueeze(0), f_s=const_feats)\n",
    "    \n",
    "out_ones = out_ones.detach()\n",
    "\n",
    "grid_visualize([content_img, style_img, out, out_ones], titles=[\"Content\", \"Style\", \"Output\", \"Constant Features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_feats = []\n",
    "for f in avg_feats:\n",
    "    rand_feats.append((torch.rand_like(f)*2-1).squeeze(0))\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_rand, _, _ = bfg_model.net(content_img.unsqueeze(0), f_s=rand_feats)\n",
    "    \n",
    "out_ones = out_ones.detach()\n",
    "\n",
    "grid_visualize([content_img, style_img, out, out_rand], titles=[\"Content\", \"Style\", \"Output\", \"Random Features\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
